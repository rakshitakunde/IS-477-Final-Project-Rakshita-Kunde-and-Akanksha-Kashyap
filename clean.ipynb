{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_dir = \"data/raw\"\n",
    "crimes_data_raw_path = os.path.join(raw_data_dir, \"crimes_2001_to_present.csv\")\n",
    "victims_data_raw_path = os.path.join(raw_data_dir, \"violence_reduction_victims.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_dir = \"data/processed\"\n",
    "crimes_data_processed_path = os.path.join(processed_data_dir, \"crimes_clean.csv\")\n",
    "victims_data_processed_path = os.path.join(processed_data_dir, \"victims_clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Helper Functions ---\n",
    "\n",
    "These are the 3 helper functions we are using to clean both datasets and add enrichment elements into through the creation of new columns that add value:\n",
    "- **standardize_column_names:** Converts all the columns names to lowercase ones with underscores\n",
    "- **clean_victims_data:** Applies all cleaning and enrichment steps to the Victims dataset\n",
    "- **clean_crimes_data:** Applies all cleaning and enrichment steps to the Crimes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_column_names(df):\n",
    "    df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_victims_data(df):\n",
    "    print(\"  Cleaning 'Victims' data...\")\n",
    "    \n",
    "    # --- Cleaning Key Fields  ---\n",
    "    if df['case_number'].isnull().sum() > 0:\n",
    "        df = df.dropna(subset=['case_number'])\n",
    "    df['case_number'] = df['case_number'].str.strip()\n",
    "    \n",
    "    # 1. Clean 'age'\n",
    "    df['age'] = df['age'].replace('UNKNOWN', pd.NA)\n",
    "    df['age'] = pd.to_numeric(df['age'], errors='coerce')\n",
    "    print(\"    - 'age' cleaned: Replaced 'UNKNOWN' and converted to numeric.\")\n",
    "\n",
    "    # 2. Clean 'sex'\n",
    "    df['sex'] = df['sex'].str.upper()\n",
    "    gender_map = {\n",
    "        \"M\": \"MALE\",\n",
    "        \"F\": \"FEMALE\",\n",
    "        \"X\": \"UNKNOWN/OTHER\",\n",
    "        \"Unknown\": \"UNKNOWN/OTHER\"\n",
    "    }\n",
    "    df['sex'] = df['sex'].map(gender_map).fillna(\"UNKNOWN/OTHER\")\n",
    "    print(\"    - 'sex' cleaned: Standardized to MALE/FEMALE/UNKNOWN-OTHER.\")\n",
    "\n",
    "    # 3. Clean 'race'\n",
    "    df['race'] = df['race'].str.upper().str.strip()\n",
    "    race_map = {\n",
    "        \"Black or African American\": \"BLACK\",\n",
    "        \"White\": \"WHITE\",\n",
    "        \"Asian/Pacific Islander\": \"ASIAN\",\n",
    "    }\n",
    "    df['race'] = df['race'].map(race_map).fillna(\"OTHER/UNKNOWN\")\n",
    "    print(\"    - 'race' cleaned: Standardized common race entries.\")\n",
    "    \n",
    "    # --- Cleaning Date Fields ---\n",
    "    date_format = '%m/%d/%Y %I:%M:%S %p'\n",
    "    df['date'] = pd.to_datetime(df['date'], format=date_format, errors='coerce')\n",
    "    print(\"    - 'date' converted to datetime object.\")\n",
    "    \n",
    "    # --- Enrichment for Privacy/Ethics ---\n",
    "    # Create a new 'age_group' column for analysis and privacy\n",
    "    age_bins = [0, 17, 25, 34, 44, 54, 64, 120]\n",
    "    age_labels = ['0-17 (Minor)', '18-25', '26-34', '35-44', '45-54', '55-64', '65+']\n",
    "    \n",
    "    df['age_group'] = pd.cut(df['age'], bins=age_bins,labels=age_labels, right=True)\n",
    "   \n",
    "    # Convert to string to avoid issues if you need to save to different formats like Parquet\n",
    "    df['age_group'] = df['age_group'].astype(str).replace('nan', pd.NA)\n",
    "    print(\"    - Enriched 'age' with new 'age_group' column.\")\n",
    "\n",
    "    cols_to_drop = ['age', 'block', 'latitude', 'longitude']\n",
    "    df = df.drop(columns=cols_to_drop, errors='ignore')\n",
    "    print(\"    - Ethics fixing by dropping high-risk QIs to create safe data.\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_crimes_data(df):\n",
    "    print(\"  Cleaning 'Crimes' data...\")\n",
    "    \n",
    "    # --- Cleaninig Key Fields ---\n",
    "    if df['case_number'].isnull().sum() > 0:\n",
    "        print(f\"    - WARNING: Found {df['case_number'].isnull().sum()} null case numbers. Dropping them.\")\n",
    "        df = df.dropna(subset=['case_number'])\n",
    "    df['case_number'] = df['case_number'].str.strip()\n",
    "\n",
    "    # --- Cleaning Date Fields ---\n",
    "    date_format = '%m/%d/%Y %I:%M:%S %p'\n",
    "    df['date'] = pd.to_datetime(df['date'], format=date_format, errors='coerce')\n",
    "    df['updated_on'] = pd.to_datetime(df['updated_on'], format=date_format, errors='coerce')\n",
    "    print(\"    - 'date' and 'updated_on' converted to datetime objects.\")\n",
    "    \n",
    "    # --- Enrichment for Time-Based Features ---\n",
    "    print(\"    - Enriching with time-based features...\")\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['day_of_week'] = df['date'].dt.day_name()\n",
    "    \n",
    "    hour = df['date'].dt.hour\n",
    "    df['time_of_day'] = pd.cut(hour,\n",
    "                               bins=[-1, 6, 12, 18, 24],\n",
    "                               labels=['Night', 'Morning', 'Afternoon', 'Evening'])\n",
    "    df['time_of_day'] = df['time_of_day'].astype(str).replace('nan', pd.NA)\n",
    "    \n",
    "    # --- Enrichment for mapping 'iucr' to categories ---\n",
    "\n",
    "    crime_map = {\n",
    "        '0110': 'HOMICIDE', '0130': 'HOMICIDE',\n",
    "        '0261': 'CRIMINAL SEXUAL ASSAULT', '0262': 'CRIMINAL SEXUAL ASSAULT',\n",
    "        '031A': 'ROBBERY', '031B': 'ROBBERY',\n",
    "        '041A': 'AGGRAVATED ASSAULT', '041B': 'AGGRAVATED ASSAULT',\n",
    "        '0460': 'BATTERY', '0486': 'BATTERY',\n",
    "        '0560': 'ASSAULT',\n",
    "        '0610': 'BURGLARY', '0620': 'BURGLARY',\n",
    "        '0810': 'THEFT', '0820': 'THEFT',\n",
    "        '0910': 'MOTOR VEHICLE THEFT', '0920': 'MOTOR VEHICLE THEFT',\n",
    "        '141A': 'WEAPONS VIOLATION', '141B': 'WEAPONS VIOLATION',\n",
    "        '1811': 'NARCOTICS', '1812': 'NARCOTICS'\n",
    "    }\n",
    "    \n",
    "    df['crime_category'] = df['iucr'].map(crime_map).fillna('OTHER')\n",
    "    print(\"    - Enriched 'iucr' with high-level 'crime_category'.\")\n",
    "\n",
    "    cols_to_drop = ['block', 'latitude', 'longitude', 'location', 'x_coordinate', 'y_coordinate']\n",
    "    df = df.drop(columns=cols_to_drop, errors='ignore')\n",
    "    print(\"    - Ethics fixing by dropping high-risk QIs (block, lat/lon, coordinates).\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- Main Cleaning Function -----\n",
    "\n",
    "This function will load, clean, enrich, and save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Data Cleaning ---\n",
      "Loading raw datasets from 'data/raw'...\n",
      "Raw datasets loaded.\n",
      "Standardized all the column names\n",
      "  Cleaning 'Victims' data...\n",
      "    - 'age' cleaned: Replaced 'UNKNOWN' and converted to numeric.\n",
      "    - 'sex' cleaned: Standardized to MALE/FEMALE/UNKNOWN-OTHER.\n",
      "    - 'race' cleaned: Standardized common race entries.\n",
      "    - 'date' converted to datetime object.\n",
      "    - Enriched 'age' with new 'age_group' column.\n",
      "    - Ethics fixing by dropping high-risk QIs to create safe data.\n",
      "  Cleaning 'Crimes' data...\n",
      "    - 'date' and 'updated_on' converted to datetime objects.\n",
      "    - Enriching with time-based features...\n",
      "    - Enriched 'iucr' with high-level 'crime_category'.\n",
      "    - Ethics fixing by dropping high-risk QIs (block, lat/lon, coordinates).\n",
      "Saving processed files to 'data/processed'...\n",
      "Columns in *clean victims* file: ['case_number', 'date', 'victimization_primary', 'incident_primary', 'gunshot_injury_i', 'unique_id', 'zip_code', 'ward', 'community_area', 'street_outreach_organization', 'area', 'district', 'beat', 'sex', 'race', 'victimization_fbi_cd', 'incident_fbi_cd', 'victimization_fbi_descr', 'incident_fbi_descr', 'victimization_iucr_cd', 'incident_iucr_cd', 'victimization_iucr_secondary', 'incident_iucr_secondary', 'homicide_victim_first_name', 'homicide_victim_mi', 'homicide_victim_last_name', 'month', 'day_of_week', 'hour', 'location_description', 'state_house_district', 'state_senate_district', 'updated', 'location', 'age_group']\n",
      "Columns in *clean crimes* file: ['id', 'case_number', 'date', 'iucr', 'primary_type', 'description', 'location_description', 'arrest', 'domestic', 'beat', 'district', 'ward', 'community_area', 'fbi_code', 'year', 'updated_on', 'month', 'day_of_week', 'time_of_day', 'crime_category']\n",
      "Success: Cleaned and enriched files saved.\n",
      "--- Data Cleaning Complete ---\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    print(\"--- Starting Data Cleaning ---\")\n",
    "    \n",
    "    os.makedirs(processed_data_dir, exist_ok=True)\n",
    "    \n",
    "    # 1. Load\n",
    "    print(f\"Loading raw datasets from '{raw_data_dir}'...\")\n",
    "    try:\n",
    "        victims_df = pd.read_csv(victims_data_raw_path, low_memory=False)\n",
    "        crimes_df = pd.read_csv(crimes_data_raw_path, low_memory=False)\n",
    "        print(\"Raw datasets loaded.\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"ERROR: Raw data files were not found. Run 'acquire.ipynb' first.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR loading raw data: {e}\")\n",
    "        return\n",
    "\n",
    "    # Standardize\n",
    "    victims_df_standardize = standardize_column_names(victims_df)\n",
    "    crimes_df_standardize = standardize_column_names(crimes_df)\n",
    "    print(\"Standardized all the column names\")\n",
    "\n",
    "    # Clean & Enrich\n",
    "    victims_df_clean = clean_victims_data(victims_df_standardize)\n",
    "    crimes_df_clean = clean_crimes_data(crimes_df_standardize)\n",
    "    \n",
    "    # Save\n",
    "    print(f\"Saving processed files to '{processed_data_dir}'...\")\n",
    "\n",
    "    print(f\"Columns in *clean victims* file: {victims_df_clean.columns.tolist()}\")\n",
    "    print(f\"Columns in *clean crimes* file: {crimes_df_clean.columns.tolist()}\")\n",
    "\n",
    "    victims_df_clean.to_csv(victims_data_processed_path, index=False)\n",
    "    crimes_df_clean.to_csv(crimes_data_processed_path, index=False)\n",
    "    \n",
    "    print(\"Success: Cleaned and enriched files saved.\")\n",
    "    print(\"--- Data Cleaning Complete ---\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
